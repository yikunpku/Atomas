version: "Atomas"  

# data
dataset: "ChEBI-20_data"
test_split: "test"
batch_size: 1
max_lenth: 512

# model
model_size: "large"
queue_size: 13200
task: "genmol"
tsclosswt: 1
lmlosswt: 10
wtilosswt: 1
encode_text_lr: 1e-4
encode_smiles_lr: 1e-4
molt5_lr: 1e-4
text_lr_scale: 0.1
smiles_lr_scale: 0.1
decay: 0

# train
precision: "bf16"
resume_from_checkpoint: "./pretrain_model_path""